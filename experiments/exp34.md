В данном опыте изучалось влияние коэффициентов начального условия($w$ и $k$) и уравнения($\alpha$) на точность и внешний вид решения. Для простоты использовалось начальное условие одного солитона.
Было проведено 18 запусков с одинаковым количеством эпох обучения, точностью разбиения и прочим, отличие было лишь в вышеперечисленных коэффициентах. На основании полученных `MSE_f_u`, `MSE_f_v`, `MSE_fl`, `MSE_sl`
были сделаны выводы о влиянии коэффициентов на точность решения.  
<img src="https://github.com/mikhakuv/PINNs/blob/main/pictures/exp34_chart1.PNG">  
<img src="https://github.com/mikhakuv/PINNs/blob/main/pictures/exp34_chart2.PNG">  
<img src="https://github.com/mikhakuv/PINNs/blob/main/pictures/exp34_chart3.PNG">  
На приведённых выше графиках видно, что:  
**1.** При увеличении $k$ точность решения существенно снижается во всех отношениях  
**2.** При увеличении $w$ точность решения немного увеличивается, тоже по всем метрикам  
**3.** При увеличении $\alpha$ точность соответствия уравнению снижается, а законам сохранения увеличивается  
Также в самих опытах было видно, что:  
**4.** При увеличении $\alpha$ солитон начинает распыляться и терять свою форму  

Из всего вышеперечисленного можно сделать вывод о том, что для достижения большей точности нужно по возможности брать $k$ как можно меньше, $w$ как можно больше, а $\alpha$ как можно ближе к 0.
Можно попробовать объяснить результаты исходя из вида уравнения и его решения:
$$iq_t + q_{xx} + |q|^2 q (1 - \alpha |q|^2 + \beta |q|^4) = 0$$
$$q(x, t)=\Bigg[\frac{4*(k^{2} - w)}{e^{\sqrt{k^2 - w} * (x - 2kt - x_0)} + 2(k^2 - w) * e^{-\sqrt{k^2 - w} * (x - 2kt - x_0)}}\Bigg] e^{i \left(k x - w t - \theta_{0}\right)}$$
Во-первых, **3.** объясняется тем, что чем ближе $\alpha$ к 0, тем проще задача оптимизации и следовательно, точнее решение.
Чтобы объяснить **1.** и **2.** нужно обратить внимание на выражение $\sqrt{k^{2} - w}$. Из его вида и положения в формуле следует, что при увеличении $k$ возрастает амплитуда, частота изменения по $t$ и в меньшей степени частота изменения по $x$. Это делает функцию более резкой и сложной для аппроксимации, что снижает точность решения.
При этом увеличение $w$ снижает значение выражения $\sqrt{k^{2} - w}$, что даёт эффект, обратный увеличению $k$, но не такой сильный ведь $w$ имеет меньшую степень.
Объяснить **4.** пока затруднительно, но это точно связано с видом уравнения, которому учится соответствовать нейросеть.
