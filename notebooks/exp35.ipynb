{"cells":[{"cell_type":"markdown","metadata":{"id":"Sgqfu6cegA2T"},"source":["Реализация PINN на pytorch взята отсюда: https://github.com/jayroxis/PINNs/blob/master/Burgers%20Equation/Burgers%20Inference%20(PyTorch).ipynb"]},{"cell_type":"markdown","metadata":{"id":"CSj6OaovBhEG"},"source":["#Уравнение второго порядка:"]},{"cell_type":"markdown","metadata":{"id":"Md2b5DS8oB47"},"source":["коэффициенты"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSE4VEP3n0IT"},"outputs":[],"source":["import math\n","alpha = 0.0\n","beta = 0.\n","k=2.0\n","w=1.7\n","x0=0.0\n","th0=0.0"]},{"cell_type":"markdown","metadata":{"id":"HIrdeugOoGEJ"},"source":["решение"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7lFQE60ucLP"},"outputs":[],"source":["def q(x,t):\n","  kexp = np.exp(np.sqrt(k ** 2 - w) * (x - 2 * k * t - x0))\n","  f_com = 4 * (k ** 2 - w) / (kexp + 2 * (k ** 2 - w) / kexp)\n","  u = f_com * np.cos(k * x - w * t + th0)\n","  v = f_com * np.sin(k * x - w * t + th0)\n","  return u, v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C6mPmy7FW508"},"outputs":[],"source":["!pip install pyDOE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESHqRF_KBd1A"},"outputs":[],"source":["import torch\n","from collections import OrderedDict #упорядоченный словарь\n","from pyDOE import lhs #функция, выбирающая значения для обучения на них нейросети\n","import numpy as np\n","import time\n","np.random.seed(1234)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-K7dJndUlAB"},"outputs":[],"source":["#можно сменить среду выполнения на gpu и обучение будет происходить быстрее\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lgsje_Ms8Vmr"},"outputs":[],"source":["class SinActivation(torch.nn.Module): #кастомная функция активации - sin\n","    def __init__(self):\n","        super(SinActivation, self).__init__()\n","        return\n","    def forward(self, x):\n","        return torch.sin(x)\n","\n","class FourierTransform(torch.nn.Module):\n","  def __init__(self):\n","    super(FourierTransform, self).__init__()\n","    return\n","  def forward(self, X):\n","    return torch.fft.rfftn(X)\n","\n","class InverseFourierTransform(torch.nn.Module):\n","  def __init__(self):\n","    super(InverseFourierTransform, self).__init__()\n","    return\n","  def forward(self, X):\n","    return torch.fft.irfftn(X)"]},{"cell_type":"markdown","metadata":{"id":"INnh3lfZpdTk"},"source":["нейросеть, в виде которой будет находиться решение"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iZq8rBGZUqMc"},"outputs":[],"source":["class FDNN(torch.nn.Module):\n","    def __init__(self, layers): #принимает на вход массив целых чисел\n","        super(FDNN, self).__init__() #вызывает метод init(почему нельзя сделать это без super?)\n","\n","        self.depth = len(layers) - 1\n","        self.activation = SinActivation #в качестве функции активации используется sin\n","        self.ft = FourierTransform #прямое дискретное преобразование Фурье\n","        self.ift = InverseFourierTransform # обратное дискретное преобразование Фурье\n","\n","        dimension_list = [0]*self.depth #лист с размерностью каждого слоя, нужно для правильной обработки 'FL'\n","        for i in range(self.depth):\n","          if (isinstance(layers[i], int)): dimension_list[i]=layers[i]\n","          elif (layers[i]=='FL'): dimension_list[i]=dimension_list[i-1]\n","\n","        layer_list = list() #список с весами и функциями активации каждого слоя\n","        for i in range(self.depth - 1):\n","          if (isinstance(layers[i], int)):\n","            layer_list.append(('layer_%d' % i, torch.nn.Linear(dimension_list[i], dimension_list[i+1]))) #каждые два слоя образуют двудольный граф\n","            layer_list.append(('activation_%d' % i, self.activation()))\n","          elif (layers[i]=='FL'):\n","            layer_list.append(('fourier_transform_%d' %i, self.ft())) #прямое преобразование Фурье\n","            layer_list.append(('layer_%d' % i, torch.nn.Linear(1+dimension_list[i-1]//2, 1+dimension_list[i+1]//2).to(torch.complex64))) #комплексное линейное преобразование\n","            layer_list.append(('inverse_fourier_transform_%d' %i, self.ift())) #обратное преобразование Фурье\n","            layer_list.append(('activation_%d' % i, self.activation())) #нелинейное преобразование на выходе\n","\n","        layer_list.append(('layer_%d' % (self.depth - 1), torch.nn.Linear(dimension_list[-2], dimension_list[-1]))) #нельзя сделать в цикле, потому что нет функции активации\n","\n","        layerDict = OrderedDict(layer_list) #сделали упорядоченный словарь, чтобы при использовании элементы выдавались в том порядке, в котором были добавлены\n","        self.layers = torch.nn.Sequential(layerDict) #собственно, задали архитектуру нейросети\n","\n","    def forward(self, x):\n","        out = self.layers(x)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"xYh7EE5hpjkO"},"source":["наконец, PINN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DqcQWmI3Uuy_"},"outputs":[],"source":["class PhysicsInformedNN():\n","    def __init__(self, X_uv, u, v, X_f, layers, lb, ub, alpha, beta):\n","\n","        # граничные условия\n","        self.lb = torch.tensor(lb).float().to(device) #левое\n","        self.ub = torch.tensor(ub).float().to(device) #правое\n","\n","        # данные для обучения\n","        self.x_uv = torch.tensor(X_uv[:, 0:1], requires_grad=True).float().to(device) #для граничных условий: (x_uv, t_uv, u, v)\n","        self.t_uv = torch.tensor(X_uv[:, 1:2], requires_grad=True).float().to(device)\n","        self.u = torch.tensor(u).float().to(device)\n","        self.v = torch.tensor(v).float().to(device)\n","        #self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device) #для уравнения: (x_f, t_f, f=0) (используются переданные сети точки)\n","        #self.t_f = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n","        self.x_f = torch.tensor((lb + (ub-lb)*lhs(2, N_f))[:, 0:1], requires_grad=True).float().to(device) #создаём N_f точек для обучения соответствия уравнению. те, что переданы, не используем\n","        self.t_f = torch.tensor((lb + (ub-lb)*lhs(2, N_f))[:, 1:2], requires_grad=True).float().to(device)\n","\n","        #данные для законов сохранения\n","        self.x_fragments = 100 #разбиение при интегрировании по x при фиксированном t\n","        self.t_amount = 10 #в скольких точках t считается интеграл\n","        x_l = np.linspace(x_0, x_1, self.x_fragments).reshape(self.x_fragments,1)\n","        t_l = np.linspace(t_0, t_1, self.t_amount).reshape(self.t_amount,1)\n","        self.x_l = torch.tensor(x_l, requires_grad=True).float().to(device)\n","        self.t_l = torch.tensor(t_l, requires_grad=True).float().to(device)\n","\n","        # числовые коэффициенты в уравнении\n","        self.alpha = alpha\n","        self.beta = beta\n","\n","        # модель\n","        self.layers = layers\n","        self.dnn = FDNN(layers).to(device)\n","\n","        # оптимизатор - LBFGS, обучает с точностью до 1e-5 или пока разница в точности уменьшается больше, чем точность float(?)\n","        self.optimizer = torch.optim.LBFGS(\n","            self.dnn.parameters(),\n","            lr=0.0001,\n","            max_iter=50000,\n","            max_eval=50000,\n","            history_size=50,\n","            tolerance_grad=1e-5,\n","            tolerance_change=1.0 * np.finfo(float).eps,\n","            #line_search_fn=\"strong_wolfe\"\n","        )\n","\n","        self.adam = torch.optim.Adam(\n","          self.dnn.parameters(),\n","          lr=0.005,\n","          betas=(0.9, 0.999),\n","          eps=1e-08,\n","          weight_decay=0,\n","          amsgrad=False)\n","\n","        self.iter = 0\n","\n","    def net_uv(self, x, t): # вывод модели\n","        u = self.dnn(torch.cat([x, t], dim=1))[:,0:1]\n","        v = self.dnn(torch.cat([x, t], dim=1))[:,1:2]\n","        return u, v\n","\n","    def net_f(self, x, t): #вывод  функции\n","        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n","        u, v = self.net_uv(x, t)\n","\n","        u_t = torch.autograd.grad(\n","            u, t,\n","            grad_outputs=torch.ones_like(u),\n","            retain_graph=True,\n","            create_graph=True\n","        )[0] #производая по t\n","        u_x = torch.autograd.grad(\n","            u, x,\n","            grad_outputs=torch.ones_like(u),\n","            retain_graph=True,\n","            create_graph=True\n","        )[0] #производная по x\n","        u_xx = torch.autograd.grad(\n","            u_x, x,\n","            grad_outputs=torch.ones_like(u_x),\n","            retain_graph=True,\n","            create_graph=True\n","        )[0] #вторая призводная по x\n","\n","        v_t = torch.autograd.grad(\n","            v, t,\n","            grad_outputs=torch.ones_like(v),\n","            retain_graph=True,\n","            create_graph=True\n","        )[0] #производая по t\n","        v_x = torch.autograd.grad(\n","            v, x,\n","            grad_outputs=torch.ones_like(v),\n","            retain_graph=True,\n","            create_graph=True\n","        )[0] #производная по x\n","        v_xx = torch.autograd.grad(\n","            v_x, x,\n","            grad_outputs=torch.ones_like(v_x),\n","            retain_graph=True,\n","            create_graph=True\n","        )[0] #вторая призводная по x\n","\n","        f_u = u*(u**2 + v**2)*(-self.alpha*(u**2 + v**2) + self.beta*(u**2 + v**2)**2 + 1) + u_xx - v_t #это и есть действительная и коплексная части исходного уравнения\n","        f_v = u_t + v*(u**2 + v**2)*(-self.alpha*(u**2 + v**2) + self.beta*(u**2 + v**2)**2 + 1) + v_xx #они получены путём подстановки q=u+i*v в него\n","        return f_u, f_v\n","\n","    def first_law(self): #реализация первого закона сохранения\n","        x_step=(self.x_l[1]-self.x_l[0]).item()\n","        initial_integral=0\n","        for j in range(0,self.x_fragments): #считаем интеграл по x в точке t_0\n","          u, v = self.net_uv(self.x_l[j:j+1], self.t_l[0:1]) #интеграл считается от вывода нейросети\n","          #u, v = q_tensor(self.x_l[j:j+1], self.t_l[0:1]) #интеграл считается от q(x,t), ведь она по сути дана в t_0\n","          initial_integral += (u**2 + v**2) * x_step\n","\n","        variation=np.zeros(self.t_amount)\n","        for i in range(1,self.t_amount): #сравниваем с интегралом по x в других точках\n","          integral=0\n","          for j in range(0,self.x_fragments):\n","            u, v = self.net_uv(self.x_l[j:j+1], self.t_l[i:i+1])\n","            integral += (u**2 + v**2) * x_step\n","          variation[i]=(initial_integral-integral)**2\n","\n","        return variation.mean(axis=0) #возвращаем средний квадрат отклонения\n","\n","    def second_law(self): #реализация второго закона сохранения\n","        x_step=(self.x_l[1]-self.x_l[0]).item()\n","        initial_integral=0\n","        for j in range(0,self.x_fragments): #считаем интеграл по x в t_0\n","          u, v = self.net_uv(self.x_l[j:j+1], self.t_l[0:1]) #интеграл считается от вывода нейросети\n","          #u, v = q_tensor(self.x_l[j:j+1], self.t_l[0:1]) #интеграл считается от q(x,t)\n","          u_x = torch.autograd.grad(u, self.x_l, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n","          v_x = torch.autograd.grad(v, self.x_l, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n","          initial_integral += ((v_x[j] * u - u_x[j] * v) * x_step)\n","\n","        variation=np.zeros(self.t_amount)\n","        for i in range(1,self.t_amount): #сравниваем с интегралом по x в других точках\n","          integral=0\n","          for j in range(0,self.x_fragments):\n","            u, v = self.net_uv(self.x_l[j:j+1], self.t_l[i:i+1])\n","            u_x = torch.autograd.grad(u, self.x_l, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0] #почему-то градиент по self.x_l[j:j+1] посчитать не получается\n","            v_x = torch.autograd.grad(v, self.x_l, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0] #поэтому вычисляется градиент по self.x_l и берётся j элемент\n","            integral += ((v_x[j] * u - u_x[j] * v) * x_step)\n","          variation[i]=(initial_integral-integral)**2\n","\n","        return variation.mean(axis=0) #опять возвращаем средний квадрат отклонения\n","\n","    def loss_func(self): #функция потерь\n","        self.optimizer.zero_grad() #обнуляет градиенты\n","\n","        u_pred, v_pred = self.net_uv(self.x_uv, self.t_uv)\n","        f_u_pred, f_v_pred = self.net_f(self.x_f, self.t_f)\n","        loss_uv = torch.mean(((self.u - u_pred) ** 2 + (self.v - v_pred) ** 2)/2) #средний квадрат всех отклонений от начальных условий\n","        loss_f = torch.mean((f_u_pred ** 2 + f_v_pred ** 2)/2) #средний квадрат всех отклонений от условия\n","\n","        loss = loss_uv + loss_f\n","\n","        loss.backward()\n","        self.iter += 1\n","        if self.iter % 1000 == 0:\n","            print('Iter %d, Loss: %.5e, Loss_uv: %.5e, Loss_f: %.5e' % (self.iter, loss.item(), loss_uv.item(), loss_f.item()))\n","            #print('loss_fl: %.5e' %loss_fl.item())\n","            #print('loss_sl: %.5e' %loss_sl.item())\n","            loss_fl = self.first_law()\n","            loss_sl = self.second_law()\n","            loss_array.append(loss.item()) #loss запоминаем для графика\n","            loss_fl_array.append(loss_fl.item()) #loss_fl и loss_sl тоже\n","            loss_sl_array.append(loss_sl.item())\n","            iter_array.append(self.iter)\n","\n","        if self.iter % 10 == 0: #каждые 10 итераций генерируем новые точки для обучения\n","          random_points = lb + (ub-lb)*lhs(2, N_f)\n","          self.x_f = torch.tensor(random_points[:, 0:1], requires_grad=True).float().to(device)\n","          self.t_f = torch.tensor(random_points[:, 1:2], requires_grad=True).float().to(device)\n","\n","        return loss\n","\n","    def train(self): #обучение\n","        adam_iterations = 30000\n","        print('training started')\n","        print('%d iterations of ADAM:' %adam_iterations)\n","        self.dnn.train()\n","        for i in range(adam_iterations): #во время тренировки производится 30000 шагов adam, а дальше запускается lbfgs\n","            if i % 100 == 0: self.adam.param_groups[0]['lr'] = 0.99*self.adam.param_groups[0]['lr'] #экспоненциальное уменьшение шага каждые 100 шагов\n","            self.adam.step(self.loss_func)\n","        #print('LBFGS:')\n","        #self.optimizer.step(self.loss_func)\n","        #print('Total iterations: %d + %d' %(adam_iterations, (self.iter-adam_iterations)))\n","\n","\n","    def predict(self, X): #вывод нейросети и функции на входных данных\n","        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n","        t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n","\n","        self.dnn.eval()\n","        u, v = self.net_uv(x, t)\n","        f_u, f_v = self.net_f(x, t)\n","        u = u.detach().cpu().numpy()\n","        v = v.detach().cpu().numpy()\n","        f_u = f_u.detach().cpu().numpy()\n","        f_v = f_v.detach().cpu().numpy()\n","        return u, v, f_u, f_v"]},{"cell_type":"markdown","metadata":{"id":"dFMEDI4_pqZL"},"source":["данные для обучения"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdohH47tU0cf"},"outputs":[],"source":["N_u = 200 # число точек, обучающих принимать граничные значения\n","N_f = 30000 # число точек, обучающих удовлетворять уравнению\n","x_parts = 1000 #число частей, на которые разбивается отрезок x\n","t_parts = 100 #число частей, на которые разбивается отрезок t\n","layers = [2, 100, 100, 'FL', 100, 100, 2]\n","\n","x_0=-10\n","x_1=30\n","t_0=0\n","t_1=3.5\n","x = np.linspace(x_0, x_1, x_parts)\n","t = np.linspace(t_0, t_1, t_parts)\n","X, T = np.meshgrid(x, t)\n","Exact_u=q(X,T)[0]\n","Exact_v=q(X,T)[1]\n","\n","X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n","u_star = Exact_u.flatten()[:,None]\n","v_star = Exact_v.flatten()[:,None]\n","\n","# границы области\n","lb = X_star.min(0)\n","ub = X_star.max(0)\n","\n","# для обучения берём только данные на границах области(граничные условия по сути)\n","xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T)) #(x,t_0)\n","uu1 = Exact_u[0:1,:].T\n","vv1 = Exact_v[0:1,:].T\n","xx2 = np.hstack((X[:,0:1], T[:,0:1])) #(x_0,t)\n","uu2 = np.zeros((t_parts,1)) #граничные условия поставил 0 в соответствии с требованиями\n","vv2 = np.zeros((t_parts,1))\n","xx3 = np.hstack((X[:,-1:], T[:,-1:])) #(x_1,t)\n","uu3 = np.zeros((t_parts,1)) #тут тоже\n","vv3 = np.zeros((t_parts,1))\n","\n","X_uv_train = np.vstack([xx1, xx2, xx3]) #данные для тренировки в точках на границе\n","u_train = np.vstack([uu1, uu2, uu3])\n","v_train = np.vstack([vv1, vv2, vv3])\n","X_f_train = lb + (ub-lb)*lhs(2, N_f) #данные для тренировки в случайных точкам из области\n","X_f_train = np.vstack((X_f_train, X_uv_train)) #добавим к ним ещё и точки на границе, там f тоже 0\n","\n","idx = np.random.choice(X_uv_train.shape[0], N_u, replace=False) #выберем из точек на границе только N_u\n","X_uv_train = X_uv_train[idx, :]\n","u_train = u_train[idx,:]\n","v_train = v_train[idx,:]\n","\n","loss_array = [] #массив с loss в процессе обучения\n","loss_fl_array = [] #массивы с loss_fl и loss_sl\n","loss_sl_array = []\n","iter_array = [] #итерации с шагом 100"]},{"cell_type":"markdown","metadata":{"id":"QwUjv7emVVqP"},"source":["Обучение"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"McQX7sQ5U9DB"},"outputs":[],"source":["model = PhysicsInformedNN(X_uv_train, u_train, v_train, X_f_train, layers, lb, ub, alpha, beta)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zAUFaIJVGZd"},"outputs":[],"source":["%%time\n","#штука сверху выведет итоговое время выполнения\n","model.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZrbXMDJHAPO"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(np.array(iter_array)[::10], np.array(loss_array)[::10], color = \"blue\")\n","plt.ylim(0,5e-4)\n","plt.title('loss(iter)')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KP6Mcf2VnITC"},"outputs":[],"source":["plt.plot(np.array(iter_array), np.array(loss_fl_array), color = \"blue\")\n","plt.ylim(0,1)\n","plt.title('loss_fl(iter)')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1u_q20np3VZg"},"outputs":[],"source":["plt.plot(np.array(iter_array), np.array(loss_sl_array), color = \"blue\")\n","plt.ylim(0,1)\n","plt.title('loss_sl(iter)')\n","plt.show()"]},{"cell_type":"code","source":["torch.save(model, 'model_12(3).pth') #сохраняем модель"],"metadata":{"id":"dPWR6n7WKORf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yOGdVkXCVIlH"},"outputs":[],"source":["u_pred, v_pred, f_u_pred, f_v_pred = model.predict(X_star) #можно ради интереса сравнить с суммой дух решений, которая строго говоря не является решением(но именно от неё и берутся начальные условия)\n","#mse_u = ((u_star-u_pred)**2).mean(axis=0).item()\n","#mse_v = ((v_star-v_pred)**2).mean(axis=0).item()\n","#mse_q = (((u_star**2+v_star**2)**0.5 - (u_pred**2+v_pred**2)**0.5)**2).mean(axis=0).item() #средний квадрат разности модулей\n","mse_f_u = ((f_u_pred)**2).mean(axis=0).item()\n","mse_f_v = ((f_v_pred)**2).mean(axis=0).item()\n","#print('MSE_u: %e, MSE_v: %e, MSE_q: %e' %(mse_u, mse_v, mse_q)) #сравнение с суммой решений, ради интереса\n","print('MSE_f_u: %e, MSE_f_v: %e' %(mse_f_u, mse_f_v))"]},{"cell_type":"markdown","metadata":{"id":"s7y79Xiye9UE"},"source":["Визуализация"]},{"cell_type":"markdown","metadata":{"id":"oiaqJnPD5SvN"},"source":["Что выдала нейросеть:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FG5HJmUQOmH7"},"outputs":[],"source":["fig, ax = plt.subplots()\n","u_min, u_max = -np.abs(u_pred).max(), np.abs(u_pred).max()\n","c = ax.pcolormesh(T, X, u_pred.reshape((t_parts, x_parts)), cmap='RdBu', vmin=u_min, vmax=u_max)\n","ax.set_title('u_pred(x,t)')\n","ax.axis([t_0, t_1, x_0, x_1])\n","fig.colorbar(c, ax=ax)\n","#plt.scatter(X_uv_train[:,1], X_uv_train[:,0], s=7, color='black')\n","#plt.scatter(X_f_train[:,1], X_f_train[:,0], s=3, color='black', alpha=0.3)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","v_min, v_max = -np.abs(v_pred).max(), np.abs(v_pred).max()\n","c = ax.pcolormesh(T, X, v_pred.reshape((t_parts, x_parts)), cmap='RdBu', vmin=v_min, vmax=v_max)\n","ax.set_title('v_pred(x,t)')\n","ax.axis([t_0, t_1, x_0, x_1])\n","fig.colorbar(c, ax=ax)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"cKcbBz-i5WJA"},"source":["Что получается при суммировании решений:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4GPMVVPdV-CW"},"outputs":[],"source":["fig, ax = plt.subplots()\n","u_min, u_max = -np.abs(Exact_u).max(), np.abs(Exact_u).max()\n","c = ax.pcolormesh(T, X, Exact_u, cmap='RdBu', vmin=u_min, vmax=u_max)\n","ax.set_title('u_sum(x,t)')\n","ax.axis([t_0, t_1, x_0, x_1])\n","fig.colorbar(c, ax=ax)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","v_min, v_max = -np.abs(Exact_v).max(), np.abs(Exact_v).max()\n","c = ax.pcolormesh(T, X, Exact_v, cmap='RdBu', vmin=v_min, vmax=v_max)\n","ax.set_title('v_sum(x,t)')\n","ax.axis([t_0, t_1, x_0, x_1])\n","fig.colorbar(c, ax=ax)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"2a-1Y7Vx5kar"},"source":["Решение в срезах по t:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJGf_wB1Afx6"},"outputs":[],"source":["t=t_0\n","while t<=t_1:\n","  current_row = int(t_parts*(t-t_0)/(t_1-t_0))\n","  if t==t_1: current_row=-1 #если смотрим значения в t_1, то ясно что это последняя колонка\n","  plt.plot(X[current_row, :], u_pred.reshape((t_parts, x_parts))[current_row,:], color = \"red\") #предсказанное решение\n","  #plt.plot(X[current_row, :], Exact_u[current_row,:], color = \"green\") #суммированное решение\n","  plt.title('u_pred(x,t=%.2f)'%t)\n","  plt.show()\n","  t+=abs(t_1-t_0)/7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VpfujHIVAmoZ"},"outputs":[],"source":["t=t_0\n","while t<=t_1:\n","  current_row = int(t_parts*(t-t_0)/(t_1-t_0))\n","  if t==t_1: current_row=-1 #если смотрим значения в t_1, то ясно что это последняя колонка\n","  plt.plot(X[current_row, :], v_pred.reshape((t_parts, x_parts))[current_row,:], color = \"red\")\n","  #plt.plot(X[current_row, :], Exact_v[current_row,:], color = \"green\")\n","  plt.title('v_pred(x,t=%.2f)'%t)\n","  plt.show()\n","  t+=abs(t_1-t_0)/7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n2oaM0bE-yq5"},"outputs":[],"source":["t=t_0\n","while t<=t_1:\n","  current_row = int(t_parts*(t-t_0)/(t_1-t_0))\n","  if t==t_1: current_row=-1 #если смотрим значения в t_1, то ясно что это последняя колонка\n","  q_abs_pred = (u_pred.reshape((t_parts, x_parts))[current_row,:]**2 + v_pred.reshape((t_parts, x_parts))[current_row,:]**2)**0.5\n","  q_abs_exact = (Exact_u[current_row,:]**2 + Exact_v[current_row,:]**2)**0.5\n","  plt.plot(X[current_row, :], q_abs_pred, color = \"red\")\n","  #plt.plot(X[current_row, :], q_abs_exact, color = \"green\")\n","  plt.title('q_abs(x,t=%.2f)'%t)\n","  plt.show()\n","  t+=abs(t_1-t_0)/7"]},{"cell_type":"markdown","metadata":{"id":"zbS54gXX5tpy"},"source":["Точность выполнения условий уравнения:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gkAaSiv-86r"},"outputs":[],"source":["loss_abs_f = (f_u_pred**2 + f_v_pred**2)**0.5 #тензор модулей значений уравнения\n","loss_abs_f_array=[]\n","t_array=[]\n","for t in np.linspace(t_0, t_1, 100):\n","  current_row = int(t_parts*(t-t_0)/(t_1-t_0))\n","  if t==t_1: current_row=-1 #если смотрим значения в t_1, то ясно что это последняя колонка\n","  loss_abs_f_array.append(loss_abs_f.reshape((t_parts, x_parts))[current_row,:].mean())\n","  t_array.append(t)\n","plt.figure(figsize=(10,4))\n","plt.plot(t_array, loss_abs_f_array, color = \"blue\")\n","plt.title('mean_x(|f(t)|)') #среднее значение модуля функции на срезе при фиксированном t\n","plt.show()\n","print('Mean_xt(|f|): %e' %loss_abs_f.mean(axis=0).item()) #среднее значение модуля функции на всей сетке"]},{"cell_type":"markdown","metadata":{"id":"A70zjI84sMw9"},"source":["Проверка законов сохранения:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y42n1oFPsSsp"},"outputs":[],"source":["import matplotlib.ticker as mtick\n","x_fragments = 400 #разбиение при интегрировании по x при фиксированном t\n","t_amount = 10 #в скольких точках t считается интеграл\n","x_l = np.linspace(x_0, x_1, x_fragments).reshape(x_fragments,1)\n","t_l = np.linspace(t_0, t_1, t_amount).reshape(t_amount,1)\n","X_l = torch.tensor(x_l, requires_grad=True).float().to(device)\n","T_l = torch.tensor(t_l, requires_grad=True).float().to(device)\n","x_step=(X_l[1]-X_l[0]).item()\n","\n","#реализация первого закона сохранения\n","u, v = model.net_uv(X_l, torch.full((x_fragments,1),T_l[0:1].item(), requires_grad=True).float().to(device))\n","initial_integral = ((u**2 + v**2) * x_step).sum() #вычисляем интеграл в t_0\n","u, v = model.net_uv(X_l.expand(x_fragments, t_amount).T.reshape(x_fragments*t_amount,1), T_l.expand(t_amount, x_fragments).reshape(x_fragments*t_amount,1))\n","first_variation = (((u.reshape(t_amount, x_fragments)**2 + v.reshape(t_amount, x_fragments)**2) * x_step).sum(axis=1) - initial_integral)**2 #вычисляем интегралы при других t и находим отклонение\n","first_variation = first_variation.detach()\n","MSE_fl = first_variation.mean(axis=0).item() #возвращаем средний квадрат отклонения\n","mean_fl = (first_variation**0.5).mean(axis=0).item() #а также средний модуль отклонения\n","plt.figure(figsize=(10,4))\n","plt.plot(t_l, (first_variation**0.5/initial_integral).detach().cpu(), color = \"blue\") #строим график соблюдения первого закона сохранения(чем ближе к 0, тем лучше)\n","plt.title('|first_int(t)-first_int(t=0)|/first_int(t=0)')\n","plt.ylim(0,1)\n","plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0)) #меняем числа на проценты\n","plt.show()\n","\n","#реализация второго закона сохранения\n","u, v = model.net_uv(X_l, torch.full((x_fragments,1),T_l[0:1].item(), requires_grad=True).float().to(device))\n","u_x = torch.autograd.grad(u, X_l, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n","v_x = torch.autograd.grad(v, X_l, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n","initial_integral = ((v_x*u - u_x*v) * x_step).sum() #вычисляем интеграл в t_0\n","X_l_expanded = X_l.expand(x_fragments, t_amount).T.reshape(x_fragments*t_amount,1)\n","T_l_expanded = T_l.expand(t_amount, x_fragments).reshape(x_fragments*t_amount,1)\n","u, v = model.net_uv(X_l_expanded, T_l_expanded)\n","u_x = torch.autograd.grad(u, X_l_expanded, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n","v_x = torch.autograd.grad(v, X_l_expanded, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n","second_variation = ((((v_x*u).reshape(t_amount, x_fragments) - (u_x*v).reshape(t_amount, x_fragments)) * x_step).sum(axis=1) - initial_integral)**2 #вычисляем интегралы при других t и находим отклонение\n","second_variation = second_variation.detach()\n","MSE_sl = second_variation.mean(axis=0).item() #возвращаем средний квадрат отклонения\n","mean_sl = (second_variation**0.5).mean(axis=0).item() #а также средний модуль отклонения\n","plt.figure(figsize=(10,4))\n","plt.plot(t_l, (second_variation**0.5/initial_integral).detach().cpu(), color = \"blue\") #строим график соблюдения первого закона сохранения(чем ближе к 0, тем лучше)\n","plt.title('|second_int(t)-second_int(t=0)|/second_int(t=0)')\n","plt.ylim(0,1)\n","plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n","plt.show()\n","\n","print('First law MSE: %e, Second law MSE: %e' %(MSE_fl, MSE_sl))\n","print('First law mean: %e, Second law mean: %e' %(mean_fl, mean_sl)) #среднее значение модуля отклонения интеграла от первоначального значения"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1nENvsBHC_1O2BVzqf6Cv-VbetbUeaEoK","timestamp":1696446383556},{"file_id":"1wWwV_1-w6nDkeKHc1_m-mMD9aLIqpWra","timestamp":1696144468068},{"file_id":"1mPbwGErE3BTRVghLdzr0gPOnjVIA-BJ7","timestamp":1695759335491},{"file_id":"1KzNVi65mSzI3563mov0HV1f4VA0PADyS","timestamp":1695755074087},{"file_id":"1x67b_shTY9pqPV0Pqx7Wa5sJ9s82LJlu","timestamp":1695196109893}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":0}